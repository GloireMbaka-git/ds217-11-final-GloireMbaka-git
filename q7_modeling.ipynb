{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4835c483",
   "metadata": {},
   "source": [
    "# Q7: Modeling\n",
    "\n",
    "**Phase 8:** Modeling  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Train multiple models, evaluate performance, compare models, extract feature importance.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 4 ([`11/demo/04_modeling_results.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/04_modeling_results.ipynb)), Phase 8. Also see Lecture 10 (modeling with sklearn and XGBoost).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "136309fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (62540, 21)\n",
      "Test set: (15637, 21)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import xgboost as xgb\n",
    "import os\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load prepared data from Q6\n",
    "X_train = pd.read_csv('output/q6_X_train.csv')\n",
    "X_test = pd.read_csv('output/q6_X_test.csv')\n",
    "y_train = pd.read_csv('output/q6_y_train.csv').squeeze()  # Convert to Series\n",
    "y_test = pd.read_csv('output/q6_y_test.csv').squeeze()\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa03494",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Train multiple models, evaluate performance, compare models, and extract feature importance.\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Data Leakage Warning\n",
    "\n",
    "If you see suspiciously perfect model performance, this likely indicates data leakage. Common warning signs:\n",
    "\n",
    "**Warning Metrics:**\n",
    "- **Perfect R¬≤ = 1.0000** (or very close, like 0.9999+)\n",
    "- **Zero or near-zero RMSE/MAE** (e.g., RMSE < 0.01¬∞C for temperature prediction)\n",
    "- **Train and test performance nearly identical** (difference < 0.01)\n",
    "- **Unrealistic precision**: Errors smaller than measurement precision (e.g., < 0.1¬∞C for temperature sensors)\n",
    "- **Feature correlation > 0.99** with target (check correlations between features and target)\n",
    "\n",
    "**Common Causes:**\n",
    "- **Circular prediction logic**: Using rolling windows of the target variable to predict itself\n",
    "  - Example: Using `air_temp_rolling_7h` to predict `Air Temperature`\n",
    "  - This is like predicting temperature from smoothed temperature - circular reasoning!\n",
    "- **Features nearly identical to target**: Any feature with correlation > 0.99 with the target\n",
    "- **Including target variable directly**: Accidentally including the target in features\n",
    "\n",
    "**How to Check:**\n",
    "- Calculate correlations between each feature and the target\n",
    "- If any feature has correlation > 0.95, investigate whether it's legitimate or leakage\n",
    "- For time series: Be especially careful with rolling windows, lag features, or any transformation of the target variable\n",
    "\n",
    "**Example of Problematic Feature:**\n",
    "- `air_temp_rolling_7h` (7-hour rolling mean of Air Temperature) when predicting Air Temperature\n",
    "- This feature has ~99.4% correlation with the target - too high to be useful and indicates circular logic\n",
    "\n",
    "**Solution:**\n",
    "- Only create rolling windows for **predictor variables**, not the target\n",
    "- Use rolling windows of: Wind Speed, Humidity, Barometric Pressure, etc.\n",
    "- Avoid rolling windows of: Air Temperature (if that's your target)\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q7_predictions.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):**\n",
    "- `actual` - Actual target values from test set\n",
    "- `predicted_linear` or `predicted_model1` - Predictions from first model (e.g., Linear Regression)\n",
    "- `predicted_xgboost` or `predicted_model2` - Predictions from second model (e.g., XGBoost)\n",
    "- Additional columns for additional models (e.g., `predicted_random_forest` or `predicted_model3`)\n",
    "\n",
    "**Requirements:**\n",
    "- Must have at least 2 model prediction columns (in addition to `actual`)\n",
    "- All values must be numeric (float)\n",
    "- Same number of rows as test set\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "actual,predicted_linear,predicted_xgboost\n",
    "15.2,14.8,15.1\n",
    "15.3,15.0,15.2\n",
    "...\n",
    "```\n",
    "\n",
    "### 2. `output/q7_model_metrics.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Performance metrics for each model\n",
    "**Required information for each model:**\n",
    "- Model name\n",
    "- At least R¬≤ score for both train and test sets (additional metrics like RMSE, MAE recommended but optional)\n",
    "\n",
    "**Requirements:**\n",
    "- Clearly labeled (model name, metric name)\n",
    "- **At minimum:** R¬≤ (or R-squared or R^2) for train and test for each model\n",
    "- Additional metrics (RMSE, MAE) are recommended for a complete analysis\n",
    "- Format should be readable\n",
    "\n",
    "**Example format (minimum - R¬≤ only):**\n",
    "```\n",
    "MODEL PERFORMANCE METRICS\n",
    "========================\n",
    "\n",
    "LINEAR REGRESSION:\n",
    "  Train R¬≤: 0.3048\n",
    "  Test R¬≤:  0.3046\n",
    "\n",
    "XGBOOST:\n",
    "  Train R¬≤: 0.9091\n",
    "  Test R¬≤:  0.7684\n",
    "```\n",
    "\n",
    "**Example format (recommended - with additional metrics):**\n",
    "```\n",
    "MODEL PERFORMANCE METRICS\n",
    "========================\n",
    "\n",
    "LINEAR REGRESSION:\n",
    "  Train R¬≤: 0.3048\n",
    "  Test R¬≤:  0.3046\n",
    "  Train RMSE: 8.42\n",
    "  Test RMSE:  8.43\n",
    "  Train MAE:  7.03\n",
    "  Test MAE:   7.04\n",
    "\n",
    "XGBOOST:\n",
    "  Train R¬≤: 0.9091\n",
    "  Test R¬≤:  0.7684\n",
    "  Train RMSE: 3.45\n",
    "  Test RMSE:  4.87\n",
    "  Train MAE:  2.58\n",
    "  Test MAE:   3.66\n",
    "```\n",
    "\n",
    "### 3. `output/q7_feature_importance.csv`\n",
    "**Format:** CSV file\n",
    "**Required Columns (exact names):** `feature`, `importance`\n",
    "**Content:** Feature importance from tree-based models (XGBoost, Random Forest)\n",
    "**Requirements:**\n",
    "- One row per feature\n",
    "- `feature`: Feature name (string)\n",
    "- `importance`: Importance score (float, typically 0-1, sum to 1)\n",
    "- Sorted by importance (descending)\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "**Note:** Tree-based models (XGBoost, Random Forest) provide feature importance directly via `.feature_importances_`. If using only Linear Regression, you can use the absolute values of coefficients as a proxy for importance.\n",
    "\n",
    "**Example:**\n",
    "```csv\n",
    "feature,importance\n",
    "Air Temperature,0.6539\n",
    "hour,0.1234\n",
    "month,0.0892\n",
    "Water Temperature,0.0456\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] At least 2 different models trained\n",
    "  - **Suggested:** Linear Regression and XGBoost (or Random Forest)\n",
    "  - You may choose other models if appropriate\n",
    "- [ ] Performance evaluated on both train and test sets\n",
    "- [ ] Models compared\n",
    "- [ ] Feature importance extracted\n",
    "  - Tree-based models: use `.feature_importances_`\n",
    "  - Linear Regression: use absolute coefficient values\n",
    "- [ ] Model performance documented with **at least R¬≤** (additional metrics like RMSE, MAE recommended)\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Check for data leakage** - Before training, compute correlations between features and target. Any feature with correlation > 0.95 should be investigated and considered for removal.\n",
    "2. **Train at least 2 models** - Fit models to training data, generate predictions for both train and test sets\n",
    "3. **Calculate metrics** - At minimum R¬≤ for train and test; RMSE and MAE recommended\n",
    "4. **Extract feature importance** - Use `.feature_importances_` for tree-based models, or coefficient magnitudes for linear models\n",
    "5. **Save predictions** - DataFrame with `actual` column plus `predicted_*` columns for each model\n",
    "6. **Save metrics** - Write clearly labeled metrics to text file\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Model selection:** Train at least 2 different models. We suggest starting with **Linear Regression** and **XGBoost** - these work well and demonstrate different modeling approaches (linear vs gradient boosting). You may choose other models if appropriate (e.g., Random Forest, Gradient Boosting, etc.). See Lecture 11 Notebook 4 for examples.\n",
    "- **Evaluation metrics:** Report at least one metric for each model. We suggest **R¬≤ score** (coefficient of determination) - it works for both Linear Regression and XGBoost, and all regression models. It measures the proportion of variance explained and is easy to interpret. Alternative metrics that work well for both models include **RMSE** (Root Mean Squared Error) or **MAE** (Mean Absolute Error). You may include additional metrics if relevant (e.g., MAPE, adjusted R¬≤). Compare train vs test performance to check for overfitting.\n",
    "- **Feature importance:** If using tree-based models (like XGBoost), extract feature importance to understand which features matter most.\n",
    "\n",
    "---\n",
    "\n",
    "## Interpreting Model Performance\n",
    "\n",
    "**Warning Signs of Data Leakage:**\n",
    "- R¬≤ = 1.0000 (perfect score) or R¬≤ > 0.999\n",
    "- RMSE or MAE = 0.0 or unrealistically small (< 0.01 for temperature)\n",
    "- Train and test performance nearly identical (difference < 0.01)\n",
    "- Any feature with correlation > 0.99 with target\n",
    "\n",
    "**Realistic Expectations:**\n",
    "- For temperature prediction: RMSE of 0.5-2.0¬∞C is realistic\n",
    "- R¬≤ of 0.85-0.98 is strong but realistic\n",
    "- Some difference between train and test performance is normal\n",
    "\n",
    "**If you see warning signs:**\n",
    "1. Check your features for data leakage (see Data Leakage Warning above)\n",
    "2. Calculate correlations between features and target\n",
    "3. Remove features that are transformations of the target variable\n",
    "4. Re-train models and verify performance is now realistic\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q7, you should have:\n",
    "- [ ] At least 2 models trained (suggested: Linear Regression and XGBoost)\n",
    "- [ ] Performance metrics calculated (at minimum: one metric like R¬≤, RMSE, or MAE for train and test; additional metrics recommended)\n",
    "- [ ] Models compared\n",
    "- [ ] Feature importance extracted (if applicable - tree-based models like XGBoost)\n",
    "- [ ] All 3 artifacts saved: `q7_predictions.csv`, `q7_model_metrics.txt`, `q7_feature_importance.csv`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q8_results.md` for Results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52075d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL EVALUATION HELPER FUNCTIONS\n",
    "\n",
    "def evaluate_model(y_true, y_pred, dataset_name=\"Dataset\"):\n",
    "    \"\"\"\n",
    "    Calculate standard regression metrics.\n",
    "\n",
    "    Demonstrates DRY principle: evaluation logic in one place.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        True values\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    dataset_name : str\n",
    "        Name for display purposes\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing RMSE, MAE, and R¬≤ scores\n",
    "    \"\"\"\n",
    "    return {\n",
    "        'dataset': dataset_name,\n",
    "        'rmse': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'mae': mean_absolute_error(y_true, y_pred),\n",
    "        'r2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "\n",
    "def assess_overfitting(train_r2, test_r2):\n",
    "    \"\"\"\n",
    "    Assess model overfitting by comparing train and test R¬≤ scores.\n",
    "\n",
    "    Overfitting gap = Train R¬≤ - Test R¬≤\n",
    "    - < 5%: Excellent generalization\n",
    "    - 5-10%: Good generalization\n",
    "    - 10-20%: Some overfitting - consider regularization\n",
    "    - > 20%: Severe overfitting - model needs adjustment\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    train_r2 : float\n",
    "        R¬≤ score on training set\n",
    "    test_r2 : float\n",
    "        R¬≤ score on test set\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple : (gap, status_message)\n",
    "    \"\"\"\n",
    "    gap = train_r2 - test_r2\n",
    "\n",
    "    if gap < 0.05:\n",
    "        return gap, \"‚úÖ Excellent generalization\"\n",
    "    elif gap < 0.10:\n",
    "        return gap, \"‚úÖ Good generalization\"\n",
    "    elif gap < 0.20:\n",
    "        return gap, \"‚ö†Ô∏è Some overfitting - consider regularization\"\n",
    "    else:\n",
    "        return gap, \"‚ùå Severe overfitting - model needs adjustment\"\n",
    "\n",
    "# Model hyperparameters\n",
    "RANDOM_SEED = 42  # For reproducible results\n",
    "\n",
    "# Random Forest hyperparameters\n",
    "RF_N_ESTIMATORS = 100  # Number of trees (more = better but slower)\n",
    "RF_MAX_DEPTH = 10      # Max tree depth (lower = less overfitting)\n",
    "\n",
    "# XGBoost hyperparameters\n",
    "XGB_N_ESTIMATORS = 100    # Number of boosting rounds\n",
    "XGB_MAX_DEPTH = 6         # Max tree depth (XGBoost default, shallower than RF)\n",
    "XGB_LEARNING_RATE = 0.1   # Step size shrinkage (lower = more conservative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8ff819a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üìä Model 1: Linear Regression"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>5.79</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>3.87</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R¬≤</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0.8946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric Training    Test\n",
       "0   RMSE     5.79    3.25\n",
       "1    MAE     3.87    2.58\n",
       "2     R¬≤   0.6771  0.8946"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Overfitting (R¬≤ difference):** -0.2175 ‚Äî ‚úÖ Excellent generalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MODELING USING A LINEAR REGRESSION\n",
    "\n",
    "# Train linear regression model\n",
    "display(Markdown(\"# üìä Model 1: Linear Regression\"))\n",
    "\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_lr = lr_model.predict(X_train)\n",
    "y_test_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "# Evaluate using helper function\n",
    "train_metrics_lr = evaluate_model(y_train, y_train_pred_lr, \"Training\")\n",
    "test_metrics_lr = evaluate_model(y_test, y_test_pred_lr, \"Test\")\n",
    "\n",
    "# Check for overfitting using helper function\n",
    "overfit_lr, overfit_status = assess_overfitting(train_metrics_lr['r2'], test_metrics_lr['r2'])\n",
    "\n",
    "display(Markdown(\"### Performance Results\"))\n",
    "display(pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE', 'R¬≤'],\n",
    "    'Training': [\n",
    "        f\"{train_metrics_lr['rmse']:.2f}\",\n",
    "        f\"{train_metrics_lr['mae']:.2f}\",\n",
    "        f\"{train_metrics_lr['r2']:.4f}\"\n",
    "    ],\n",
    "    'Test': [\n",
    "        f\"{test_metrics_lr['rmse']:.2f}\",\n",
    "        f\"{test_metrics_lr['mae']:.2f}\",\n",
    "        f\"{test_metrics_lr['r2']:.4f}\"\n",
    "    ]\n",
    "}))\n",
    "display(Markdown(f\"**Overfitting (R¬≤ difference):** {overfit_lr:.4f} ‚Äî {overfit_status}\"))\n",
    "\n",
    "# Store for comparison later\n",
    "train_rmse_lr, test_rmse_lr = train_metrics_lr['rmse'], test_metrics_lr['rmse']\n",
    "train_mae_lr, test_mae_lr = train_metrics_lr['mae'], test_metrics_lr['mae']\n",
    "train_r2_lr, test_r2_lr = train_metrics_lr['r2'], test_metrics_lr['r2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb280a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üöÄ Model 3: XGBoost"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.69</td>\n",
       "      <td>2.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R¬≤</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric Training    Test\n",
       "0   RMSE     1.69    2.13\n",
       "1    MAE     1.00    1.19\n",
       "2     R¬≤   0.9727  0.9545"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Overfitting (R¬≤ difference):** 0.0181 ‚Äî ‚úÖ Excellent generalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# XGBOOST REGRESSION\n",
    "\n",
    "# Train XGBoost model\n",
    "display(Markdown(\"# üöÄ Model 3: XGBoost\"))\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=XGB_N_ESTIMATORS,\n",
    "    max_depth=XGB_MAX_DEPTH,\n",
    "    learning_rate=XGB_LEARNING_RATE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_xgb = xgb_model.predict(X_train)\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate using helper function\n",
    "train_metrics_xgb = evaluate_model(y_train, y_train_pred_xgb, \"Training\")\n",
    "test_metrics_xgb = evaluate_model(y_test, y_test_pred_xgb, \"Test\")\n",
    "\n",
    "# Check for overfitting using helper function\n",
    "overfit_xgb, overfit_status = assess_overfitting(train_metrics_xgb['r2'], test_metrics_xgb['r2'])\n",
    "\n",
    "display(Markdown(\"### Performance Results\"))\n",
    "display(pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE', 'R¬≤'],\n",
    "    'Training': [\n",
    "        f\"{train_metrics_xgb['rmse']:.2f}\",\n",
    "        f\"{train_metrics_xgb['mae']:.2f}\",\n",
    "        f\"{train_metrics_xgb['r2']:.4f}\"\n",
    "    ],\n",
    "    'Test': [\n",
    "        f\"{test_metrics_xgb['rmse']:.2f}\",\n",
    "        f\"{test_metrics_xgb['mae']:.2f}\",\n",
    "        f\"{test_metrics_xgb['r2']:.4f}\"\n",
    "    ]\n",
    "}))\n",
    "display(Markdown(f\"**Overfitting (R¬≤ difference):** {overfit_xgb:.4f} ‚Äî {overfit_status}\"))\n",
    "\n",
    "# Store for comparison later\n",
    "train_rmse_xgb, test_rmse_xgb = train_metrics_xgb['rmse'], test_metrics_xgb['rmse']\n",
    "train_mae_xgb, test_mae_xgb = train_metrics_xgb['mae'], test_metrics_xgb['mae']\n",
    "train_r2_xgb, test_r2_xgb = train_metrics_xgb['r2'], test_metrics_xgb['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96d67b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üå≤ Model 2: Random Forest"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Performance Results"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>1.68</td>\n",
       "      <td>2.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R¬≤</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric Training    Test\n",
       "0   RMSE     1.68    2.19\n",
       "1    MAE     0.97    1.14\n",
       "2     R¬≤   0.9729  0.9521"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Overfitting (R¬≤ difference):** 0.0208 ‚Äî ‚úÖ Excellent generalization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#3. MODELING USING RANDOM FOREST\n",
    "\n",
    "display(Markdown(\"# üå≤ Model 2: Random Forest\"))\n",
    "\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=RF_N_ESTIMATORS,\n",
    "    max_depth=RF_MAX_DEPTH,\n",
    "    random_state=RANDOM_SEED,\n",
    "    n_jobs=-1  # Use all CPU cores\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_train_pred_rf = rf_model.predict(X_train)\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate using helper function\n",
    "train_metrics_rf = evaluate_model(y_train, y_train_pred_rf, \"Training\")\n",
    "test_metrics_rf = evaluate_model(y_test, y_test_pred_rf, \"Test\")\n",
    "\n",
    "# Check for overfitting using helper function\n",
    "overfit_rf, overfit_status = assess_overfitting(train_metrics_rf['r2'], test_metrics_rf['r2'])\n",
    "\n",
    "display(Markdown(\"### Performance Results\"))\n",
    "display(pd.DataFrame({\n",
    "    'Metric': ['RMSE', 'MAE', 'R¬≤'],\n",
    "    'Training': [\n",
    "        f\"{train_metrics_rf['rmse']:.2f}\",\n",
    "        f\"{train_metrics_rf['mae']:.2f}\",\n",
    "        f\"{train_metrics_rf['r2']:.4f}\"\n",
    "    ],\n",
    "    'Test': [\n",
    "        f\"{test_metrics_rf['rmse']:.2f}\",\n",
    "        f\"{test_metrics_rf['mae']:.2f}\",\n",
    "        f\"{test_metrics_rf['r2']:.4f}\"\n",
    "    ]\n",
    "}))\n",
    "display(Markdown(f\"**Overfitting (R¬≤ difference):** {overfit_rf:.4f} ‚Äî {overfit_status}\"))\n",
    "\n",
    "# Store for comparison later\n",
    "train_rmse_rf, test_rmse_rf = train_metrics_rf['rmse'], test_metrics_rf['rmse']\n",
    "train_mae_rf, test_mae_rf = train_metrics_rf['mae'], test_metrics_rf['mae']\n",
    "train_r2_rf, test_r2_rf = train_metrics_rf['r2'], test_metrics_rf['r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ceca47ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üîë Top 10 Most Important Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wet Bulb Temperature</td>\n",
       "      <td>0.563762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.186979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wet Bulb Temperature_24h_mean</td>\n",
       "      <td>0.110632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wet_bulb_humidity_ratio</td>\n",
       "      <td>0.059212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Station Name_Foster Weather Station</td>\n",
       "      <td>0.014335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wet_bulb_humidity_interaction</td>\n",
       "      <td>0.014194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>solar_totalrain_interaction</td>\n",
       "      <td>0.010981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Total Rain_24h_mean</td>\n",
       "      <td>0.010471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rain_difference</td>\n",
       "      <td>0.010005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total Rain</td>\n",
       "      <td>0.008841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  importance\n",
       "3                  Wet Bulb Temperature    0.563762\n",
       "2                                 month    0.186979\n",
       "12        Wet Bulb Temperature_24h_mean    0.110632\n",
       "4               wet_bulb_humidity_ratio    0.059212\n",
       "16  Station Name_Foster Weather Station    0.014335\n",
       "5         wet_bulb_humidity_interaction    0.014194\n",
       "8           solar_totalrain_interaction    0.010981\n",
       "13                  Total Rain_24h_mean    0.010471\n",
       "6                       rain_difference    0.010005\n",
       "7                            Total Rain    0.008841"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# EXTRACT FEATURE OF IMPORTANCE FRM THE RANDOM FOREST MODELS\n",
    "\n",
    "# Extract feature importance from the trained model\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "display(Markdown(\"### üîë Top 10 Most Important Features\"))\n",
    "display(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "638b1be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üîë Top 10 Most Important Features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wet Bulb Temperature</td>\n",
       "      <td>0.421717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>month</td>\n",
       "      <td>0.176276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wet Bulb Temperature_24h_mean</td>\n",
       "      <td>0.111071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wet_bulb_humidity_ratio</td>\n",
       "      <td>0.077784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>solar_totalrain_interaction</td>\n",
       "      <td>0.045034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Station Name_Foster Weather Station</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wet_bulb_humidity_interaction</td>\n",
       "      <td>0.035538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rain_difference</td>\n",
       "      <td>0.030417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heading</td>\n",
       "      <td>0.013777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pressure_humidity_interaction</td>\n",
       "      <td>0.013350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                feature  importance\n",
       "3                  Wet Bulb Temperature    0.421717\n",
       "2                                 month    0.176276\n",
       "12        Wet Bulb Temperature_24h_mean    0.111071\n",
       "4               wet_bulb_humidity_ratio    0.077784\n",
       "8           solar_totalrain_interaction    0.045034\n",
       "16  Station Name_Foster Weather Station    0.038246\n",
       "5         wet_bulb_humidity_interaction    0.035538\n",
       "6                       rain_difference    0.030417\n",
       "9                               Heading    0.013777\n",
       "11        pressure_humidity_interaction    0.013350"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4. EXTRACT FEATURES OF IMPORTANCE FROM THE TRAINED MODEL from the XGBOOST\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "display(Markdown(\"### üîë Top 10 Most Important Features\"))\n",
    "display(xgb_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37c8baf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# üèÜ Model Comparison"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train RMSE</th>\n",
       "      <th>Test RMSE</th>\n",
       "      <th>Train R¬≤</th>\n",
       "      <th>Test R¬≤</th>\n",
       "      <th>Overfitting</th>\n",
       "      <th>RMSE_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>5.7949</td>\n",
       "      <td>3.2504</td>\n",
       "      <td>0.6771</td>\n",
       "      <td>0.8946</td>\n",
       "      <td>-0.2175</td>\n",
       "      <td>2.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1.6798</td>\n",
       "      <td>2.1916</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>-0.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>2.1347</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>0.9545</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>-0.4489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Train RMSE  Test RMSE  Train R¬≤  Test R¬≤  Overfitting  \\\n",
       "0  Linear Regression      5.7949     3.2504    0.6771   0.8946      -0.2175   \n",
       "1      Random Forest      1.6798     2.1916    0.9729   0.9521       0.0208   \n",
       "2            XGBoost      1.6858     2.1347    0.9727   0.9545       0.0181   \n",
       "\n",
       "   RMSE_diff  \n",
       "0     2.5445  \n",
       "1    -0.5118  \n",
       "2    -0.4489  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#5. COMPARE ALL MODELS\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Linear Regression','Random Forest' ,'XGBoost'],\n",
    "    'Train RMSE': [train_rmse_lr,train_rmse_rf,train_rmse_xgb],\n",
    "    'Test RMSE': [test_rmse_lr,test_rmse_rf,test_rmse_xgb],\n",
    "    'Train R¬≤': [train_r2_lr, train_r2_rf ,train_r2_xgb],\n",
    "    'Test R¬≤': [test_r2_lr, test_r2_rf ,test_r2_xgb],\n",
    "    'Overfitting': [overfit_lr,overfit_rf,overfit_xgb]\n",
    "})\n",
    "\n",
    "comparison = comparison.round(4)\n",
    "comparison['RMSE_diff'] = comparison['Train RMSE'] - comparison['Test RMSE']\n",
    "\n",
    "display(Markdown(\"# üèÜ Model Comparison\"))\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2096d3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved predictions to output/q7_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "#SAVING OUTPUT\n",
    "\n",
    "pred_df = pd.DataFrame({\n",
    "    \"actual_value\": y_test.values,\n",
    "    \"predicted_linear\": y_test_pred_lr,\n",
    "    \"predicted_xgboost\":y_test_pred_xgb,\n",
    "    \"predicted_random_forest\": y_test_pred_rf,\n",
    "})\n",
    "\n",
    "pred_df.to_csv(\"output/q7_predictions.csv\", index=False)\n",
    "print(f\"\\nSaved predictions to output/q7_predictions.csv\")\n",
    "\n",
    "# SAVE PERFORMANCE METRICS FOR EACH MODEL AS TEXT FILE\n",
    "\n",
    "with open(\"output/q7_model_metrics.txt\", \"w\") as f:\n",
    "    f.write(\"Linear Regression\\n\")\n",
    "    f.write(f\"Train R¬≤: {train_r2_lr:.4f}\\n\")\n",
    "    f.write(f\"Test R¬≤: {test_r2_lr:.4f}\\n\")\n",
    "    f.write(f\"Train RMSE: {train_rmse_lr:.2f}\\n\")\n",
    "    f.write(f\"Test RMSE: {test_rmse_lr:.2f}\\n\")\n",
    "    f.write(f\"Train MAE: {train_mae_lr:.2f}\\n\")\n",
    "    f.write(f\"Test MAE: {test_mae_lr:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Random Forest\\n\")\n",
    "    f.write(f\"Train R¬≤: {train_r2_rf:.4f}\\n\")\n",
    "    f.write(f\"Test R¬≤: {test_r2_rf:.4f}\\n\")\n",
    "    f.write(f\"Train RMSE: {train_rmse_rf:.2f}\\n\")\n",
    "    f.write(f\"Test RMSE: {test_rmse_rf:.2f}\\n\")\n",
    "    f.write(f\"Train MAE: {train_mae_rf:.2f}\\n\")\n",
    "    f.write(f\"Test MAE: {test_mae_rf:.2f}\\n\\n\")\n",
    "    \n",
    "    f.write(\"XGBoost\\n\")\n",
    "    f.write(f\"Train R¬≤: {train_r2_xgb:.4f}\\n\")\n",
    "    f.write(f\"Test R¬≤: {test_r2_xgb:.4f}\\n\")\n",
    "    f.write(f\"Train RMSE: {train_rmse_xgb:.2f}\\n\")\n",
    "    f.write(f\"Test RMSE: {test_rmse_xgb:.2f}\\n\")\n",
    "    f.write(f\"Train MAE: {train_mae_xgb:.2f}\\n\")\n",
    "    f.write(f\"Test MAE: {test_mae_xgb:.2f}\\n\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8b60860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Feature Importance Comparison ===\n",
      "                                    feature  random_forest   xgboost\n",
      "3                      Wet Bulb Temperature       0.563762  0.421717\n",
      "2                                     month       0.186979  0.176276\n",
      "12            Wet Bulb Temperature_24h_mean       0.110632  0.111071\n",
      "4                   wet_bulb_humidity_ratio       0.059212  0.077784\n",
      "8               solar_totalrain_interaction       0.010981  0.045034\n",
      "16      Station Name_Foster Weather Station       0.014335  0.038246\n",
      "5             wet_bulb_humidity_interaction       0.014194  0.035538\n",
      "6                           rain_difference       0.010005  0.030417\n",
      "9                                   Heading       0.001017  0.013777\n",
      "11            pressure_humidity_interaction       0.002656  0.013350\n",
      "13                      Total Rain_24h_mean       0.010471  0.011988\n",
      "14                        Humidity_24h_mean       0.004091  0.006307\n",
      "0                                      hour       0.000556  0.003567\n",
      "1                               day_of_week       0.001602  0.003238\n",
      "18                  humidity_category_humid       0.000028  0.003074\n",
      "15            wind_speed_category_very_slow       0.000031  0.002645\n",
      "17  Station Name_Oak Street Weather Station       0.000116  0.002316\n",
      "10                                 Humidity       0.000435  0.001837\n",
      "19         humidity_category_slightly_humid       0.000045  0.001817\n",
      "7                                Total Rain       0.008841  0.000000\n",
      "20             humidity_category_very_humid       0.000012  0.000000\n"
     ]
    }
   ],
   "source": [
    "#SAVING IMPORTANCE FEATURES\n",
    "\n",
    "importance_comparison = pd.DataFrame({\n",
    "    \"feature\": X_train.columns,\n",
    "    \"random_forest\": rf_model.feature_importances_,\n",
    "    \"xgboost\": xgb_model.feature_importances_,\n",
    "}).sort_values(\"xgboost\", ascending=False)\n",
    "\n",
    "print(\"\\n=== Feature Importance Comparison ===\")\n",
    "print(importance_comparison)\n",
    "\n",
    "importance_comparison.to_csv(\"output/q7_feature_importance.csv\", index=False)\n",
    "\n",
    "with open(\"output/q7_feature_importance.txt\", \"w\") as f:\n",
    "    for _, row in importance_comparison.iterrows():\n",
    "        f.write(f\"{row['feature']}: {row['random_forest']:.4f}: {row['xgboost']:.4f}, \\n\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
