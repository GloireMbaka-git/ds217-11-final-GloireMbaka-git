{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b3d469",
   "metadata": {},
   "source": [
    "# Q2: Data Cleaning\n",
    "\n",
    "**Phase 3:** Data Cleaning & Preprocessing  \n",
    "**Points: 9 points**\n",
    "\n",
    "**Focus:** Handle missing data, outliers, validate data types, remove duplicates.\n",
    "\n",
    "**Lecture Reference:** Lecture 11, Notebook 1 ([`11/demo/01_setup_exploration_cleaning.ipynb`](https://github.com/christopherseaman/datasci_217/blob/main/11/demo/01_setup_exploration_cleaning.ipynb)), Phase 3. Also see Lecture 05 (data cleaning).\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a377e3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station Name                    object\n",
      "Measurement Timestamp           object\n",
      "Air Temperature                float64\n",
      "Wet Bulb Temperature           float64\n",
      "Humidity                         int64\n",
      "Rain Intensity                 float64\n",
      "Interval Rain                  float64\n",
      "Total Rain                     float64\n",
      "Precipitation Type             float64\n",
      "Wind Direction                   int64\n",
      "Wind Speed                     float64\n",
      "Maximum Wind Speed             float64\n",
      "Barometric Pressure            float64\n",
      "Solar Radiation                  int64\n",
      "Heading                        float64\n",
      "Battery Life                   float64\n",
      "Measurement Timestamp Label     object\n",
      "Measurement ID                  object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Load data from Q1 (or directly from source)\n",
    "df = pd.read_csv('data/beach_sensors.csv')\n",
    "rows_before = len(df)\n",
    "print(df.dtypes)      # Check data types before cleaning \n",
    "# If you saved cleaned data from Q1, you can load it:\n",
    "# df = pd.read_csv('output/q1_exploration.csv')  # This won't work - load original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e6b0ea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Clean the dataset by handling missing data, outliers, validating data types, and removing duplicates.\n",
    "\n",
    "**Time Series Note:** For time series data, forward-fill (`ffill()`) is often appropriate for missing values since sensor readings are continuous. However, you may choose other strategies based on your analysis.\n",
    "\n",
    "---\n",
    "\n",
    "## Required Artifacts\n",
    "\n",
    "You must create exactly these 3 files in the `output/` directory:\n",
    "\n",
    "### 1. `output/q2_cleaned_data.csv`\n",
    "**Format:** CSV file\n",
    "**Content:** Cleaned dataset with same structure as original (same columns)\n",
    "**Requirements:**\n",
    "- Same columns as original dataset\n",
    "- Missing values handled (filled, dropped, or imputed)\n",
    "- Outliers handled (removed, capped, or transformed)\n",
    "- Data types validated and converted\n",
    "- Duplicates removed\n",
    "- **Sanity check:** Dataset should retain most rows after cleaning (at least 1,000 rows). If you're removing more than 50% of data, reconsider your strategy—imputation is usually preferable to dropping rows for this dataset.\n",
    "- **No index column** (save with `index=False`)\n",
    "\n",
    "### 2. `output/q2_cleaning_report.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Detailed report of cleaning operations\n",
    "**Required information:**\n",
    "- Rows before cleaning: [number]\n",
    "- Missing data handling method: [description]\n",
    "  - Which columns had missing data\n",
    "  - Method used (drop, forward-fill, impute, etc.)\n",
    "  - Number of values handled\n",
    "- Outlier handling: [description]\n",
    "  - Detection method (IQR, z-scores, domain knowledge)\n",
    "  - Which columns had outliers\n",
    "  - Method used (remove, cap, transform)\n",
    "  - Number of outliers handled\n",
    "- Duplicates removed: [number]\n",
    "- Data type conversions: [list any conversions]\n",
    "- Rows after cleaning: [number]\n",
    "\n",
    "**Example format:**\n",
    "```\n",
    "DATA CLEANING REPORT\n",
    "====================\n",
    "\n",
    "Rows before cleaning: 50000\n",
    "\n",
    "Missing Data Handling:\n",
    "- Water Temperature: 2500 missing values (5.0%)\n",
    "  Method: Forward-fill (time series appropriate)\n",
    "  Result: All missing values filled\n",
    "  \n",
    "- Air Temperature: 1500 missing values (3.0%)\n",
    "  Method: Forward-fill, then median imputation for remaining\n",
    "  Result: All missing values filled\n",
    "\n",
    "Outlier Handling:\n",
    "- Water Temperature: Detected 500 outliers using IQR method (3×IQR)\n",
    "  Method: Capped at bounds [Q1 - 3×IQR, Q3 + 3×IQR]\n",
    "  Bounds: [-5.2, 35.8]\n",
    "  Result: 500 values capped\n",
    "\n",
    "Duplicates Removed: 0\n",
    "\n",
    "Data Type Conversions:\n",
    "- Measurement Timestamp: Converted to datetime64[ns]\n",
    "\n",
    "Rows after cleaning: 50000\n",
    "```\n",
    "\n",
    "### 3. `output/q2_rows_cleaned.txt`\n",
    "**Format:** Plain text file\n",
    "**Content:** Single integer number (total rows after cleaning)\n",
    "**Requirements:**\n",
    "- Only the number, no text, no labels\n",
    "- No whitespace before or after\n",
    "- Example: `50000`\n",
    "\n",
    "---\n",
    "\n",
    "## Requirements Checklist\n",
    "\n",
    "- [ ] Missing data handling strategy chosen and implemented\n",
    "- [ ] Outliers detected and handled (IQR method, z-scores, or domain knowledge)\n",
    "- [ ] Data types validated and converted\n",
    "- [ ] Duplicates identified and removed\n",
    "- [ ] Cleaning decisions documented in report\n",
    "- [ ] All 3 required artifacts saved with exact filenames\n",
    "\n",
    "---\n",
    "\n",
    "## Your Approach\n",
    "\n",
    "1. **Handle missing data** - Choose appropriate strategy (drop, forward-fill, impute) based on data characteristics\n",
    "2. **Detect and handle outliers** - Use IQR method or z-scores; decide whether to remove, cap, or transform\n",
    "3. **Validate data types** - Ensure numeric and datetime columns are properly typed\n",
    "4. **Remove duplicates**\n",
    "5. **Document and save** - Write detailed cleaning report explaining your decisions\n",
    "\n",
    "---\n",
    "\n",
    "## Decision Points\n",
    "\n",
    "- **Missing data:** Should you drop rows, impute values, or forward-fill? Consider: How much data is missing? Is it random or systematic? For time series, forward-fill is often appropriate.\n",
    "- **Outliers:** Are they errors or valid extreme values? Use IQR method or z-scores to detect, then decide: remove, cap, or transform. Document your reasoning.\n",
    "- **Data types:** Are numeric columns actually numeric? Are datetime columns properly formatted? Convert as needed.\n",
    "\n",
    "---\n",
    "\n",
    "## Checkpoint\n",
    "\n",
    "After Q2, you should have:\n",
    "- [ ] Missing data handled\n",
    "- [ ] Outliers addressed\n",
    "- [ ] Data types validated\n",
    "- [ ] Duplicates removed\n",
    "- [ ] All 3 artifacts saved: `q2_cleaned_data.csv`, `q2_cleaning_report.txt`, `q2_rows_cleaned.txt`\n",
    "\n",
    "---\n",
    "\n",
    "**Next:** Continue to `q3_data_wrangling.md` for Data Wrangling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c5a636ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "HANDLING MISSING DATA\n",
      "================================================================================\n",
      "Air Temperature: 75 missing (0.0%)\n",
      "Wet Bulb Temperature: 75974 missing (38.7%)\n",
      "Rain Intensity: 75974 missing (38.7%)\n",
      "Total Rain: 75974 missing (38.7%)\n",
      "Precipitation Type: 75974 missing (38.7%)\n",
      "Barometric Pressure: 146 missing (0.1%)\n",
      "Heading: 75974 missing (38.7%)\n",
      "\n",
      "Applying forward-fill for time series data...\n",
      "Numeric columns to process: ['Air Temperature', 'Wet Bulb Temperature', 'Humidity', 'Rain Intensity', 'Interval Rain', 'Total Rain', 'Precipitation Type', 'Wind Direction', 'Wind Speed', 'Maximum Wind Speed', 'Barometric Pressure', 'Solar Radiation', 'Heading', 'Battery Life']\n",
      "\n",
      "Missing values after handling: 0\n",
      "Air Temperature: 97 outliers detected (Lower: 97, Upper: 0)\n",
      "\n",
      "Air Temperature:\n",
      "  Q1: 4.30, Q3: 21.50, IQR: 17.20\n",
      "  Bounds: [-21.50, 47.30]\n",
      "  Outliers detected: 97 (97 low, 0 high)\n",
      "Wet Bulb Temperature: 279 outliers detected (Lower: 279, Upper: 0)\n",
      "\n",
      "Wet Bulb Temperature:\n",
      "  Q1: 3.20, Q3: 17.60, IQR: 14.40\n",
      "  Bounds: [-18.40, 39.20]\n",
      "  Outliers detected: 279 (279 low, 0 high)\n",
      "Humidity: 185 outliers detected (Lower: 185, Upper: 0)\n",
      "\n",
      "Humidity:\n",
      "  Q1: 57.00, Q3: 80.00, IQR: 23.00\n",
      "  Bounds: [22.50, 114.50]\n",
      "  Outliers detected: 185 (185 low, 0 high)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_19416\\87710976.py:28: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[col] = df[col].fillna(method='ffill')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rain Intensity: 6621 outliers detected (Lower: 0, Upper: 6621)\n",
      "\n",
      "Rain Intensity:\n",
      "  Q1: 0.00, Q3: 0.00, IQR: 0.00\n",
      "  Bounds: [0.00, 0.00]\n",
      "  Outliers detected: 6621 (0 low, 6621 high)\n",
      "Interval Rain: 15851 outliers detected (Lower: 1, Upper: 15850)\n",
      "\n",
      "Interval Rain:\n",
      "  Q1: 0.00, Q3: 0.00, IQR: 0.00\n",
      "  Bounds: [0.00, 0.00]\n",
      "  Outliers detected: 15851 (1 low, 15850 high)\n",
      "Total Rain: 11621 outliers detected (Lower: 0, Upper: 11621)\n",
      "\n",
      "Total Rain:\n",
      "  Q1: 11.00, Q3: 198.20, IQR: 187.20\n",
      "  Bounds: [-269.80, 479.00]\n",
      "  Outliers detected: 11621 (0 low, 11621 high)\n",
      "Precipitation Type: 12668 outliers detected (Lower: 0, Upper: 12668)\n",
      "\n",
      "Precipitation Type:\n",
      "  Q1: 0.00, Q3: 0.00, IQR: 0.00\n",
      "  Bounds: [0.00, 0.00]\n",
      "  Outliers detected: 12668 (0 low, 12668 high)\n",
      "Wind Direction: 0 outliers detected (Lower: 0, Upper: 0)\n",
      "Wind Speed: 12221 outliers detected (Lower: 0, Upper: 12221)\n",
      "\n",
      "Wind Speed:\n",
      "  Q1: 1.60, Q3: 3.30, IQR: 1.70\n",
      "  Bounds: [-0.95, 5.85]\n",
      "  Outliers detected: 12221 (0 low, 12221 high)\n",
      "Maximum Wind Speed: 4024 outliers detected (Lower: 0, Upper: 4024)\n",
      "\n",
      "Maximum Wind Speed:\n",
      "  Q1: 1.20, Q3: 5.20, IQR: 4.00\n",
      "  Bounds: [-4.80, 11.20]\n",
      "  Outliers detected: 4024 (0 low, 4024 high)\n",
      "Barometric Pressure: 4611 outliers detected (Lower: 2883, Upper: 1728)\n",
      "\n",
      "Barometric Pressure:\n",
      "  Q1: 990.20, Q3: 998.60, IQR: 8.40\n",
      "  Bounds: [977.60, 1011.20]\n",
      "  Outliers detected: 4611 (2883 low, 1728 high)\n",
      "Solar Radiation: 29486 outliers detected (Lower: 13, Upper: 29473)\n",
      "\n",
      "Solar Radiation:\n",
      "  Q1: 0.00, Q3: 131.00, IQR: 131.00\n",
      "  Bounds: [-196.50, 327.50]\n",
      "  Outliers detected: 29486 (13 low, 29473 high)\n",
      "Heading: 27532 outliers detected (Lower: 27532, Upper: 0)\n",
      "\n",
      "Heading:\n",
      "  Q1: 351.00, Q3: 358.00, IQR: 7.00\n",
      "  Bounds: [340.50, 368.50]\n",
      "  Outliers detected: 27532 (27532 low, 0 high)\n",
      "Battery Life: 6 outliers detected (Lower: 6, Upper: 0)\n",
      "\n",
      "Battery Life:\n",
      "  Q1: 11.90, Q3: 15.10, IQR: 3.20\n",
      "  Bounds: [7.10, 19.90]\n",
      "  Outliers detected: 6 (6 low, 0 high)\n",
      "Data types after conversion:\n",
      " Station Name                    object\n",
      "Measurement Timestamp           object\n",
      "Air Temperature                float64\n",
      "Wet Bulb Temperature           float64\n",
      "Humidity                       float64\n",
      "Rain Intensity                 float64\n",
      "Interval Rain                  float64\n",
      "Total Rain                     float64\n",
      "Precipitation Type             float64\n",
      "Wind Direction                   int64\n",
      "Wind Speed                     float64\n",
      "Maximum Wind Speed             float64\n",
      "Barometric Pressure            float64\n",
      "Solar Radiation                float64\n",
      "Heading                        float64\n",
      "Battery Life                   float64\n",
      "Measurement Timestamp Label     object\n",
      "Measurement ID                  object\n",
      "dtype: object\n",
      "Duplicate rows found: 0\n",
      "Rows after removing duplicates: 196367\n"
     ]
    }
   ],
   "source": [
    "# 1. Data Cleaning\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HANDLING MISSING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check for missing values\n",
    "missing_before = df.isnull().sum()\n",
    "missing_data_info = {}\n",
    "\n",
    "for col in df.columns:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / rows_before) * 100\n",
    "        missing_data_info[col] = {\n",
    "            'count': missing_count,\n",
    "            'percentage': missing_pct\n",
    "        }\n",
    "        print(f\"{col}: {missing_count} missing ({missing_pct:.1f}%)\")\n",
    "\n",
    "# Handle missing data for numeric columns\n",
    "print(\"\\nApplying forward-fill for time series data...\")\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "print(\"Numeric columns to process:\", numeric_columns.tolist())\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if df[col].isnull().sum() > 0:\n",
    "        # Forward-fill (appropriate for time series)\n",
    "        df[col] = df[col].fillna(method='ffill')\n",
    "        \n",
    "        # If there are still missing values, use median\n",
    "        if df[col].isnull().sum() > 0:\n",
    "            median_value = df[col].median()\n",
    "            df[col] = df[col].fillna(median_value)\n",
    "            print(f\"  {col}: Forward-filled, then median imputed ({median_value:.2f})\")\n",
    "\n",
    "# Handle missing data for datetime\n",
    "\n",
    "    if df['Measurement Timestamp'].isnull().sum() > 0:\n",
    "        df = df.dropna(subset=[col])\n",
    "        print(f\"  {col}: Dropped rows with missing measurement timestamps\")\n",
    "\n",
    "print(f\"\\nMissing values after handling: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# Outliers detection and removal using IQR method\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    \n",
    "    # Count outliers\n",
    "    outlier_info = {}\n",
    "    \n",
    "    outliers_lower = (df[col] < lower_bound).sum()\n",
    "    outliers_upper = (df[col] > upper_bound).sum()\n",
    "    total_outliers = outliers_lower + outliers_upper\n",
    "    print(f\"{col}: {total_outliers} outliers detected (Lower: {outliers_lower}, Upper: {outliers_upper})\")\n",
    "\n",
    "    if total_outliers > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Q1: {Q1:.2f}, Q3: {Q3:.2f}, IQR: {IQR:.2f}\")\n",
    "        print(f\"  Bounds: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "        print(f\"  Outliers detected: {total_outliers} ({outliers_lower} low, {outliers_upper} high)\")\n",
    "        \n",
    "    outlier_info[col] = {\n",
    "            'count': total_outliers,\n",
    "            'lower_bound': lower_bound,\n",
    "            'upper_bound': upper_bound\n",
    "        }\n",
    "    \n",
    "    # Cap the outliers\n",
    "    df[col] = df[col].clip(lower=lower_bound, upper=upper_bound)\n",
    "\n",
    "\n",
    "#data types validated and converted if necessary\n",
    "for col in df.columns:\n",
    "    if col in numeric_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "print(\"Data types after conversion:\\n\", df.dtypes)\n",
    "\n",
    "# Convert Measurement timestamp to datetime\n",
    "if 'Measurement Timestamp' in df.columns:\n",
    "    df['Measurement Timestamp'] = pd.to_datetime(df['Measurement Timestamp'])\n",
    "\n",
    "\n",
    "#Duplicates removal\n",
    "duplicates_before = df.duplicated().sum()\n",
    "print(f\"Duplicate rows found: {duplicates_before}\")\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "rows_after = len(df)\n",
    "\n",
    "print(f\"Rows after removing duplicates: {rows_after}\")\n",
    "\n",
    "\n",
    "# Save cleaned data\n",
    "df.to_csv(\"output/q2_cleaned_data.csv\", index=False)\n",
    "rows_after = len(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a3752f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: output/q2_cleaning_report.txt\n"
     ]
    }
   ],
   "source": [
    "#2. REPORTING THE ANALYSIS RESULTS\n",
    "\n",
    "report = []\n",
    "report.append(\"DATA CLEANING REPORT\")\n",
    "report.append(\"=\" * 20)\n",
    "report.append(\"\")\n",
    "report.append(f\"Rows before cleaning: {rows_before}\")\n",
    "report.append(\"\")\n",
    "\n",
    "# Missing data section\n",
    "report.append(\"Missing Data Handling:\")\n",
    "if missing_data_info:\n",
    "    for col, info in missing_data_info.items():\n",
    "        report.append(f\"- {col}: {info['count']} missing values ({info['percentage']:.1f}%)\")\n",
    "        report.append(f\"  Method: Forward-fill (time series)\")\n",
    "        report.append(f\"  Result: All missing values filled\")\n",
    "        report.append(\"\")\n",
    "else:\n",
    "    report.append(\"- No missing values detected\")\n",
    "    report.append(\"\")\n",
    "\n",
    "# Outlier section\n",
    "report.append(\"Outlier Handling:\")\n",
    "if outlier_info:\n",
    "    for col, info in outlier_info.items():\n",
    "        report.append(f\"- {col}: Detected {info['count']} outliers using IQR method (3×IQR)\")\n",
    "        report.append(f\"  Method: Capped outliers\")\n",
    "        report.append(f\"  Bounds: [{info['lower_bound']:.2f}, {info['upper_bound']:.2f}]\")\n",
    "        report.append(f\"  Result: {info['count']} value capped\")\n",
    "        report.append(\"\")\n",
    "else:\n",
    "    report.append(\"- No outliers detected\")\n",
    "    report.append(\"\")\n",
    "\n",
    "# Duplicates section\n",
    "report.append(f\"Duplicates Removed: {duplicates_before}\")\n",
    "report.append(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# Save report\n",
    "report_text = '\\n'.join(report)\n",
    "with open('output/q2_cleaning_report.txt', 'w') as f:\n",
    "    f.write(report_text)\n",
    "print(\"✓ Saved: output/q2_cleaning_report.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5cf497d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: output/q2_rows_cleaned.txt\n"
     ]
    }
   ],
   "source": [
    "#3. SAVE ROWS AFTER CLEANING\n",
    "with open('output/q2_rows_cleaned.txt', 'w') as f:\n",
    "    f.write(str(rows_after))\n",
    "print(\"✓ Saved: output/q2_rows_cleaned.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39af8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision\n",
    "# I used ffill for missing numeric data because the dataset is time series based, making it appropriate to carry forward the last known value for any remaining missing.\n",
    "# we had Air Temperature: 75 missing (0.0%), Wet Bulb Temperature: 75974 missing (38.7%), Rain Intensity: 75974 missing (38.7%), Total Rain: 75974 missing (38.7%)\n",
    "#Precipitation Type: 75974 missing (38.7%), Barometric Pressure: 146 missing (0.1%), Heading: 75974 missing (38.7%). After ffill, any remaining missing at the start were filled with median.\n",
    "#At the end, we had 0 missing values. \n",
    "# I used the IQR methods to detect outliers. I believe these outliers were errors in the data entry. I chose to cap the outliers them since  we need to preserve the data samples to produce accurate values for time series analysis to produce accurate results.\n",
    "# Yes, numeric columns were really numeric. However, the measurement timestamp needed to be converted to datetime. "
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
